{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests, sys\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import logging\n",
    "from botocore.exceptions import ClientError\n",
    "import psycopg2 \n",
    "# Leer de las variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "AWS_ACCESS_KEY_ID=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_DEFAULT_REGION = os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "AWS_SESSION_TOKEN=os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "S3_BUCKET_NAME=os.getenv(\"S3_BUCKET_NAME\")\n",
    "RDS_HOSTNAME = os.getenv(\"RDS_HOSTNAME\")\n",
    "RDS_USERNAME = os.getenv(\"RDS_USERNAME\")\n",
    "RDS_PASSWORD = os.getenv(\"RDS_PASSWORD\")\n",
    "RDS_DBNAME = os.getenv(\"RDS_DBNAME\")\n",
    "RDS_PORT = os.getenv(\"RDS_PORT\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAZL2GRGDTDJD3JII7\n",
      "postgres\n",
      "5432\n"
     ]
    }
   ],
   "source": [
    "print(AWS_ACCESS_KEY_ID)\n",
    "print(RDS_USERNAME)\n",
    "print(RDS_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'QJ63PR3ZBJNS417N',\n",
       "  'HostId': '7E4RlpAw4LS7hKB0iUh0/buyQa+44/99MycUIyh4Goe37wwVAvX3asPALqZBkS54ZsCZUu3pB5b4KF/+RXld7Rb67qdVXIQV',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '7E4RlpAw4LS7hKB0iUh0/buyQa+44/99MycUIyh4Goe37wwVAvX3asPALqZBkS54ZsCZUu3pB5b4KF/+RXld7Rb67qdVXIQV',\n",
       "   'x-amz-request-id': 'QJ63PR3ZBJNS417N',\n",
       "   'date': 'Sat, 19 Oct 2024 06:32:20 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Owner': {'DisplayName': 'awslabsc0w4643792t1666354872',\n",
       "  'ID': '4ec064f8672ee90fab63463ef248c7cf04d0d237ac7de2cbde9409ebca112912'},\n",
       " 'Grants': [{'Grantee': {'DisplayName': 'awslabsc0w4643792t1666354872',\n",
       "    'ID': '4ec064f8672ee90fab63463ef248c7cf04d0d237ac7de2cbde9409ebca112912',\n",
       "    'Type': 'CanonicalUser'},\n",
       "   'Permission': 'FULL_CONTROL'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBA DE CONEXION\n",
    "s3 = boto3.client(\n",
    "    's3', \n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN,)\n",
    "result = s3.get_bucket_acl(Bucket=S3_BUCKET_NAME)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **REVISAR: ubicacion en local_file_path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Descargar un archivo desde S3\n",
    "def download_file_from_s3(bucket, s3_file_name, local_file_path):\n",
    "    s3_client = boto3.client('s3', \n",
    "                             aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                             aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "                             aws_session_token=AWS_SESSION_TOKEN)\n",
    "    try:\n",
    "        s3_client.download_file(bucket, s3_file_name, local_file_path)\n",
    "        print(f\"Archivo descargado exitosamente a {local_file_path}\")\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parámetros de S3\n",
    "bucket_name = S3_BUCKET_NAME  # Nombre de tu bucket S3\n",
    "s3_file_name = 'input-data/ensembl_ENSG00000139618_20241017_200540.csv'\n",
    "local_file_path = 'ensembl_ENSG00000139618_download.csv'\n",
    "#local_file_path=\"/tmp/ensembl_data.csv\"  # Ruta local para almacenar temporalmente el archivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\tmp\\ensembl_data.csv\n"
     ]
    }
   ],
   "source": [
    "'''import os\n",
    "\n",
    "# Obtener la ruta absoluta del archivo\n",
    "local_file_path = os.path.abspath(\"/tmp/ensembl_data.csv\" )\n",
    "print(local_file_path)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carpeta 'tmp' ya existe.\n"
     ]
    }
   ],
   "source": [
    "'''import os\n",
    "\n",
    "# Verifica si la carpeta 'data' existe\n",
    "folder_path = r'c:\\tmp\\ensembl_data.csv'\n",
    "if not os.path.exists(folder_path):\n",
    "    print(\"La carpeta 'tmp' no existe. Creando carpeta...\")\n",
    "    os.makedirs(folder_path)\n",
    "else:\n",
    "    print(\"La carpeta 'tmp' ya existe.\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo descargado exitosamente a ensembl_ENSG00000139618_download.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Descargar el archivo desde S3\n",
    "download_file_from_s3(bucket_name, s3_file_name, local_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesamiento completado.\n",
      "  feature_type  strand                         alleles clinical_significance  \\\n",
      "0    variation       1  CATCCACAACCACACACCGACCACTCTA,-               Unknown   \n",
      "1    variation       1                             A,C               Unknown   \n",
      "2    variation       1                             C,A               Unknown   \n",
      "3    variation       1                          CTTT,-               Unknown   \n",
      "4    variation       1                         TTTT,TT               Unknown   \n",
      "\n",
      "  consequence_type     start       end  \n",
      "0   intron_variant  32315059  32315086  \n",
      "1   intron_variant  32315086  32315086  \n",
      "2   intron_variant  32315089  32315089  \n",
      "3   intron_variant  32315089  32315092  \n",
      "4   intron_variant  32315090  32315093  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar datos CSV localmente (descargado de S3)\n",
    "data = pd.read_csv(local_file_path)\n",
    "\n",
    "# 1. Manejo de valores vacíos en 'clinical_significance'\n",
    "data['clinical_significance'] = data['clinical_significance'].apply(\n",
    "    lambda x: 'Unknown' if x == '[]' else x)\n",
    "\n",
    "# 2. Convertir 'alleles' a texto plano\n",
    "data['alleles'] = data['alleles'].str.strip(\"[]\").str.replace(\"'\", \"\").str.replace(\" \", \"\")\n",
    "\n",
    "# 3. Eliminar columnas innecesarias\n",
    "columns_to_drop = ['source', 'assembly_name', 'seq_region_name', 'id']\n",
    "data_filtered = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# 4. Agrupación de la variable 'clinical_significance'\n",
    "def group_clinical_significance(value):\n",
    "    if 'benign' in value:\n",
    "        return 'benign'\n",
    "    elif 'pathogenic' in value:\n",
    "        return 'pathogenic'\n",
    "    elif 'uncertain significance' in value:\n",
    "        return 'uncertain_significance'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "data_filtered['clinical_significance'] = data_filtered['clinical_significance'].apply(group_clinical_significance)\n",
    "\n",
    "# Mostrar el resultado del preprocesamiento\n",
    "print(\"Preprocesamiento completado.\")\n",
    "print(data_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar los datos preprocesados en un archivo CSV local (temporal)\n",
    "preprocessed_file_path = \"preprocessed_data.csv\"\n",
    "data_filtered.to_csv(preprocessed_file_path, index=False)\n",
    "# Guardar datos preprocesados en la base de datos RDS (PostgreSQL)\n",
    "def save_to_rds2(dataframe):\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=RDS_HOSTNAME,\n",
    "            user=RDS_USERNAME,\n",
    "            password=RDS_PASSWORD,\n",
    "            dbname=RDS_DBNAME,\n",
    "            port=RDS_PORT\n",
    "        )\n",
    "        cursor = conn.cursor()\n",
    "        for index, row in dataframe.iterrows():\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO preprocessed_data (consequence_type, alleles, start, end, clinical_significance) VALUES (%s, %s, %s, %s, %s)\",\n",
    "                (row['consequence_type'], row['alleles'], row['start'], row['end'], row['clinical_significance'])\n",
    "            )\n",
    "        conn.commit()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"Datos guardados exitosamente en RDS.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar los datos en RDS: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDS Connected!\n"
     ]
    }
   ],
   "source": [
    "# Conectar a base de datos\n",
    "import psycopg2 as ps\n",
    "try:\n",
    "    connps = ps.connect(host=RDS_HOSTNAME,database=RDS_DBNAME,user=RDS_USERNAME,password=RDS_PASSWORD,port=RDS_PORT)\n",
    "except ps.OperationalError as e:\n",
    "    raise e\n",
    "else:\n",
    "    print('RDS Connected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para guardar los datos en la tabla preprocessed_data de RDS\n",
    "def save_to_rds(dataframe):\n",
    "    try:\n",
    "        # Conectar a la base de datos PostgreSQL\n",
    "        conn = psycopg2.connect(\n",
    "            host=RDS_HOSTNAME,\n",
    "            user=RDS_USERNAME,\n",
    "            password=RDS_PASSWORD,\n",
    "            dbname=RDS_DBNAME,\n",
    "            port=RDS_PORT\n",
    "        )\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Insertar los datos en la tabla preprocessed_data\n",
    "        for index, row in dataframe.iterrows():\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO preprocessed_data (feature_type, strand, alleles, clinical_significance, consequence_type, start, \"end\")\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "                \"\"\", \n",
    "                (row['feature_type'], row['strand'], row['alleles'], row['clinical_significance'], row['consequence_type'], row['start'], row['end'])\n",
    "            )\n",
    "        \n",
    "        # Confirmar los cambios en la base de datos\n",
    "        conn.commit()\n",
    "        print(\"Datos guardados exitosamente en RDS.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al guardar los datos en RDS: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Cerrar la conexión\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres\n"
     ]
    }
   ],
   "source": [
    "print(RDS_USERNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Llamar a la función para guardar los datos en RDS\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43msave_to_rds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_filtered\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m, in \u001b[0;36msave_to_rds\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Insertar los datos en la tabla preprocessed_data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m dataframe\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;43m        INSERT INTO preprocessed_data (feature_type, strand, alleles, clinical_significance, consequence_type, start, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;43m        VALUES (\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m);\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstrand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malleles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclinical_significance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconsequence_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Confirmar los cambios en la base de datos\u001b[39;00m\n\u001b[0;32m     24\u001b[0m conn\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[1;32mc:\\Users\\lilia\\miniconda3\\envs\\cloud_estudiante\\lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Llamar a la función para guardar los datos en RDS\n",
    "save_to_rds(data_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud_estudiante",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
